{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weed detection",
      "provenance": [],
      "authorship_tag": "ABX9TyOzZ8XwMe/JPtxJ+hLw5rWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirala-noir/WEED-DETECTION-for-pesticidal-activity/blob/main/weed_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_qy-Cjz1xr"
      },
      "source": [
        "# import library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb-Wfv1R0T8s"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "#path1 = r'C:\\Users\\hp\\Desktop\\Capstone project\\dataset'\n",
        "#print(os.listdir(path1))\n",
        "\n",
        "import sys\n",
        "#pathcv = r'C:\\Users\\hp\\Anaconda3\\envs\\opencv-env\\Lib\\site-packages'\n",
        "#sys.path.append(pathcv)\n",
        "\n",
        "import cv2\n",
        "from sklearn import utils\n",
        "\n",
        "from skimage.transform import rescale, resize\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HUAYuz60i90"
      },
      "source": [
        "#Defining Image Path and Assigning Labels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F58gpaRE0oMU"
      },
      "source": [
        "def image_path(img_type, img_number):\n",
        "    \n",
        "    #image_type: 'images' #original image, 'annotations' #crop-weed label, 'mask' #vegetation segmentation\n",
        "    #image_number: the number on the image name\n",
        "    \n",
        "    image_name = img_type[:-1]\n",
        "    if img_number < 10:\n",
        "        path = 'C:/Users/hp/Desktop/Capstone project/dataset/'+str(img_type)+'/00'+str(img_number)+'_'+str(image_name)+'.png'\n",
        "    else:\n",
        "        path = 'C:/Users/hp/Desktop/Capstone project/dataset/'+str(img_type)+'/0'+str(img_number)+'_'+str(image_name)+'.png'\n",
        "    return path\n",
        "\n",
        "# generating labels for each image\n",
        "def label_generator(number):\n",
        "    annotation = cv2.imread(image_path('annotations', number))\n",
        "    height = annotation.shape[0]\n",
        "    width = annotation.shape[1]\n",
        "   # channel = annotation.shape[2]\n",
        "    labels = np.zeros((height, width, 3))\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            if np.all(annotation[i,j,:] == np.array([0,255,0])):\n",
        "                labels[i,j,0] = 1\n",
        "            elif np.all(annotation[i,j,:] == np.array([0,0,255])):\n",
        "                labels[i,j,1] = 1\n",
        "            elif np.all(annotation[i,j,:] == np.array([0,0,0])):\n",
        "                labels[i,j,2] = 1\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SZGHRAk0tRd"
      },
      "source": [
        "# rescaling the image\n",
        "\n",
        "# we rescale the image so as to get a smaller image, which reduces our calculations and in longer run also reduces \n",
        "# time complexity and computations.\n",
        "\n",
        "image = cv2.imread(image_path('annotations',1))\n",
        "image_rescaled = rescale(image, 1.0 / 6.0, anti_aliasing=True)\n",
        "plt.imshow(image_rescaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTNe4tEp0z-J"
      },
      "source": [
        "# Load two images\n",
        "img1 = cv2.imread(image_path('images',1))\n",
        "img2 = cv2.imread(image_path('masks',1))\n",
        "\n",
        "# I want to put logo on top-left corner, So I create a ROI\n",
        "rows,cols,channels = img2.shape\n",
        "roi = img1[0:rows, 0:cols ]\n",
        "\n",
        "# Now create a mask of logo and create its inverse mask also\n",
        "img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
        "ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
        "mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "# Now black-out the area of logo in ROI\n",
        "img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
        "\n",
        "# Take only region of logo from logo image.\n",
        "img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
        "\n",
        "# Put logo in ROI and modify the main image\n",
        "dst = cv2.add(img1_bg,img2_fg)\n",
        "img1[0:rows, 0:cols ] = dst\n",
        "plt.imshow(img1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4f4uJwM01Zd"
      },
      "source": [
        "label = label_generator(1)\n",
        "plt.figure()\n",
        "\n",
        "#plt.imshow(label)\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(label[:,:,i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZY3pOhx01ke"
      },
      "source": [
        "x_train = np.zeros((120, 161, 216, 3))\n",
        "y_train = np.zeros((120, 161, 216, 3))\n",
        "x_test = np.zeros((20, 161, 216, 3))\n",
        "y_test = np.zeros((20, 161, 216, 3))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "for i in range(40):\n",
        "    image = cv2.imread(image_path('images',i+1))\n",
        "    image_rescaled = rescale(image, 1.0 / 6.0, anti_aliasing=True)\n",
        "    label = label_generator(i+1)\n",
        "    label_rescaled = rescale(label, 1.0 / 6.0, anti_aliasing=True)\n",
        "    x_train[i,:,:,:] = image_rescaled\n",
        "    y_train[i,:,:,:] = label_rescaled\n",
        "    x_train[40+i,:,:,:] = np.fliplr(image_rescaled)\n",
        "    y_train[40+i,:,:,:] = np.fliplr(label_rescaled)\n",
        "    x_train[80+1,:,:,:] = np.flipud(image_rescaled)\n",
        "    y_train[80+i,:,:,:] = np.flipud(label_rescaled)\n",
        "    plt.subplot(8,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[i,:,:,:])\n",
        "    \n",
        "for i in range(20):\n",
        "    image = cv2.imread(image_path('images',i+41))\n",
        "    image_rescaled = rescale(image, 1.0 / 6.0, anti_aliasing=True)\n",
        "    label = label_generator(i+41)\n",
        "    label_rescaled = rescale(label, 1.0 / 6.0, anti_aliasing=True)\n",
        "    x_test[i,:,:,:] = image_rescaled\n",
        "    y_test[i,:,:,:] = label_rescaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpqp9hpG01mH"
      },
      "source": [
        "plt.figure()\n",
        "#plt.imshow(y_train[i,:,:])\n",
        "for i in range(40):\n",
        "    plt.subplot(8,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(y_train[i,:,:,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIH7Z_zz01ss"
      },
      "source": [
        "# functions for metrics evaluation\n",
        "\n",
        "# defining a softmax function for our model\n",
        "def depth_softmax(matrix):\n",
        "    sigmoid = lambda x: 1 / (1 + K.exp(-x))\n",
        "    sigmoided_matrix = sigmoid(matrix)\n",
        "    softmax_matrix = sigmoided_matrix / K.sum(sigmoided_matrix, axis=0)\n",
        "    return softmax_matrix\n",
        "\n",
        "# defining a recall function for our model\n",
        "# recall means the accuracy of predicting the negative class.\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# defining a precision function for our model\n",
        "# precision means the accuracy of predicting the positive class\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "# defining a f1 function for computing the f1 score\n",
        "# f1 score  = 2* precision*recall/precision + recall\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "'''\n",
        "Mean Intersection-Over-Union is a common evaluation metric for semantic image segmentation, \n",
        "which first computes the IOU for each semantic class and then computes the average over classes.\n",
        "IOU is defined as follows: IOU = true_positive / (true_positive + false_positive + false_negative).\n",
        "'''\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)\n",
        "\n",
        "'''\n",
        "Binary cross entropy is just a special case of categorical cross entropy. The equation for binary cross entropy\n",
        "loss is the exact equation for categorical cross entropy loss with one output node. For example, binary cross \n",
        "entropy with one output node is the equivalent of categorical cross entropy with two output nodes.\n",
        "'''\n",
        "def weighted_binary_cross_entropy(y_true, y_pred):\n",
        "    w = tf.reduce_sum(y_true)/tf.cast(tf.size(y_true), tf.float32)\n",
        "    real_th = 0.5-(1.0/2.0)\n",
        "    tf_th = tf.fill(tf.shape(y_pred), real_th) \n",
        "    tf_zeros = tf.fill(tf.shape(y_pred), 0.)\n",
        "    return (1.0 - w) * y_true * - tf.log(tf.maximum(tf.zeros, tf.sigmoid(y_pred) + tf_th)) + (1- y_true) * w * -tf.log(1 - tf.maximum(tf_zeros, tf.sigmoid(y_pred) + tf_th))\n",
        "#return weighted_binary_cross_entropy\n",
        "\n",
        "# assigning weights to target according to output\n",
        "def class_weighted_pixelwise_crossentropy(target, output):\n",
        "    output = tf.clip_by_value(output, 10e-8, 1.-10e-8)\n",
        "    weights = [0.8, 0.2]\n",
        "    return -tf.reduce_sum(target * weights * tf.log(output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaweUVtS01uP"
      },
      "source": [
        "# defining an activation function\n",
        "def BatchActivate(x):\n",
        "    # using batch normalization\n",
        "    x = BatchNormalization()(x)\n",
        "    # using relu activation function\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# defining a convolutional block\n",
        "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
        "    # using a strides of 1 by 1 with a activation function\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    if activation == True:\n",
        "        x = BatchActivate(x)\n",
        "    return x\n",
        "\n",
        "# defining a residual block\n",
        "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
        "    x = BatchActivate(blockInput)\n",
        "    x = convolution_block(x, num_filters, (3,3) )\n",
        "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    if batch_activate:\n",
        "        x = BatchActivate(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf_oIjqu1FWb"
      },
      "source": [
        "# defining our model\n",
        "\n",
        "def unet_res(n_classes = 1, start_neurons = 16, DropoutRatio = 0.5, img_height=161,img_width=216):\n",
        "    # 101 -> 50\n",
        "    # defining the input layer\n",
        "    input_layer = Input((img_height, img_width, 3))\n",
        "    # padding, initially adding zeros to input layer\n",
        "    zero_pad = ZeroPadding2D(padding=((7,8),(4,4)))(input_layer)\n",
        "    \n",
        "    # starting with convolutional layer\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(zero_pad)\n",
        "    # adding residual blocks\n",
        "    conv1 = residual_block(conv1,start_neurons * 1)\n",
        "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
        "    \n",
        "    # max pooling applied \n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    # dropout to avoid overfitting\n",
        "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
        "\n",
        "    # 50 -> 25\n",
        "    # starting with convolutional layer\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    # adding residual blocks\n",
        "    conv2 = residual_block(conv2,start_neurons * 2)\n",
        "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
        "    # adding pooling\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    # dropout to avoid overfitting\n",
        "    pool2 = Dropout(DropoutRatio)(pool2)\n",
        "\n",
        "    # 25 -> 12\n",
        "    # starting with convolutional layer\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    # adding residual blocks\n",
        "    conv3 = residual_block(conv3,start_neurons * 4)\n",
        "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
        "    # adding max pooling\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    # adding dropout\n",
        "    pool3 = Dropout(DropoutRatio)(pool3)\n",
        "\n",
        "    # 12 -> 6\n",
        "    # starting wit convolutional layer\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    # adding residual blocks\n",
        "    conv4 = residual_block(conv4,start_neurons * 8)\n",
        "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
        "    # adding max pooling layer\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    # adding dropout\n",
        "    pool4 = Dropout(DropoutRatio)(pool4)\n",
        "\n",
        "    # Middle\n",
        "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "    convm = residual_block(convm,start_neurons * 16)\n",
        "    convm = residual_block(convm,start_neurons * 16, True)\n",
        "    \n",
        "    # 6 -> 12\n",
        "    # transpose convolutional layer 4\n",
        "    # going backward of convolution operation, it is the core idea of transposed convolution.\n",
        "    # used as up sampling method\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    # concatinating the convolutional 4 and transposed convolutional layers 4\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    # adding dropout\n",
        "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
        "    \n",
        "    # adding it to the architecture \n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
        "    \n",
        "    # 12 -> 25\n",
        "    # transposed convolutional layer 3\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
        "    # adding convolutional layer 3 to transposed convolutional layer 3\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "    # adding dropout\n",
        "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
        "    \n",
        "    # adding it to the architecture\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
        "\n",
        "    # 25 -> 50\n",
        "    # transposed convolutional layer 2\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    # adding convolutional layer 2 and transposed convolutional layer 2\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "    # adding dropout\n",
        "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
        "    \n",
        "    # adding it to the architecture\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
        "    \n",
        "    # 50 -> 101\n",
        "    # transposed convolutional layer 1\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
        "    # adding convolutional layer 1 and transposed convolutional layer 1\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    # adding dropout\n",
        "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
        "    \n",
        "    # adding it to the architecture\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
        "    \n",
        "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
        "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "    \n",
        "    # output layer\n",
        "    output_layer_noActi = Conv2D(n_classes, (1,1), padding=\"same\", activation=None)(uconv1)\n",
        "    output_layer = Cropping2D(cropping=((7,8),(4,4)))(output_layer_noActi)\n",
        "    \n",
        "    # defining the output layer\n",
        "    # reshaping the images to defined width and height\n",
        "    if n_classes == 1:\n",
        "        output_layer = (Reshape((img_height, img_width),\n",
        "                          input_shape=(img_height, img_width, 3)))(output_layer)\n",
        "    else:\n",
        "        output_layer = (Reshape((img_height, img_width, n_classes),\n",
        "                          input_shape=(img_height, img_width, 3)))(output_layer)\n",
        "    \n",
        "    # defining the activation for output layer to be sigmoid\n",
        "    output_layer =  Activation('sigmoid')(output_layer)\n",
        "    \n",
        "    # finalizing our model\n",
        "    model = Model(input_layer, output_layer)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJO2wjzy1FfQ"
      },
      "source": [
        "# looking at the summary of the training model\n",
        "\n",
        "trial_model = unet_res(n_classes = 1, start_neurons=16)\n",
        "trial_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCs65t-Z1Fjk"
      },
      "source": [
        "# getting the bg model\n",
        "bg_model = unet_res(n_classes=1)\n",
        "\n",
        "# compiling the model\n",
        "bg_model.compile(loss = 'binary_crossentropy',\n",
        "             optimizer = 'Adam',\n",
        "             metrics = [f1, mean_iou])\n",
        "\n",
        "# using early stoppinng and reduce learning on plateau to avoid overfitting\n",
        "callbacks_bg = [\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ReduceLROnPlateau(patience=3, verbose=1),\n",
        "    ModelCheckpoint('model-bg-cwfid.h5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "# feeding training data to bg model\n",
        "model_bg_history = bg_model.fit(x = x_train,\n",
        "                         y = y_train[:,:,:,2],\n",
        "                         batch_size = 5,\n",
        "                         epochs = 20,\n",
        "                         verbose = 1,\n",
        "                         validation_split = 0.3,\n",
        "                          callbacks = callbacks_bg\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oanN2T3y1Fpr"
      },
      "source": [
        "# getting the weed model\n",
        "weed_model = unet_res(n_classes=1)\n",
        "\n",
        "# compiling the compile\n",
        "# optimizer used is adam optimizer\n",
        "# metrics used are f1 and mean_iou as defined above\n",
        "weed_model.compile(loss = 'binary_crossentropy',\n",
        "             optimizer = 'Adam',\n",
        "             metrics = [f1, mean_iou])\n",
        "\n",
        "# using early stopping to stop when the model stops learning\n",
        "callbacks_weed = [\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ReduceLROnPlateau(patience=3, verbose=1),\n",
        "    ModelCheckpoint('model-weed-cwfid.h5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "# feeding the model with training data\n",
        "model_weed_history = weed_model.fit(x = x_train,\n",
        "                         y = y_train[:,:,:,1],\n",
        "                         batch_size = 5,\n",
        "                         epochs = 20,\n",
        "                         verbose = 1,\n",
        "                         validation_split = 0.2,\n",
        "                          callbacks = callbacks_weed\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UnfsG9L1REa"
      },
      "source": [
        "# getting the crop model\n",
        "crop_model = unet_res(n_classes=1)\n",
        "\n",
        "# compiling the crop_model with adam optimizer\n",
        "crop_model.compile(loss = 'binary_crossentropy',\n",
        "             optimizer = 'Adam',\n",
        "             metrics = [f1, mean_iou])\n",
        "\n",
        "# using early stopping to stop when the model stops learning\n",
        "callbacks_crop = [\n",
        "    EarlyStopping(patience=5, verbose=1),\n",
        "    ReduceLROnPlateau(patience=3, verbose=1),\n",
        "    ModelCheckpoint('model-crop-cwfid.h5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "# feeding training data to crop_model\n",
        "model_crop_history = crop_model.fit(x = x_train,\n",
        "                         y = y_train[:,:,:,0],\n",
        "                         batch_size = 5,\n",
        "                         epochs = 20,\n",
        "                         verbose = 1,\n",
        "                         validation_split = 0.3,\n",
        "                          callbacks = callbacks_crop\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ZiEL8i1RN3"
      },
      "source": [
        "# predictions for all the three models\n",
        "\n",
        "pred_bg = bg_model.predict(x_test)\n",
        "pred_weed = weed_model.predict(x_test)\n",
        "pred_crop = crop_model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZJM1S-31RPt"
      },
      "source": [
        "# looking at the images predicted by all model for weeds and crops.\n",
        "\n",
        "i = 15\n",
        "plt.figure()\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(pred_bg[i,:,:])\n",
        "plt.subplot(2,3,4)\n",
        "plt.imshow(y_test[i,:,:,2])\n",
        "plt.subplot(2,3,2)\n",
        "plt.imshow(pred_weed[i,:,:])\n",
        "plt.subplot(2,3,5)\n",
        "plt.imshow(y_test[i,:,:,1])\n",
        "plt.subplot(2,3,3)\n",
        "plt.imshow(pred_crop[i,:,:])\n",
        "plt.subplot(2,3,6)\n",
        "plt.imshow(y_test[i,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJwK_FOZ1Z2B"
      },
      "source": [
        "# combining all the model\n",
        "full_model = unet_res(n_classes=3)\n",
        "\n",
        "# compiling the model\n",
        "full_model.compile(loss = 'binary_crossentropy',\n",
        "             optimizer = 'Adam',\n",
        "             metrics = [f1, mean_iou])\n",
        "\n",
        "# using early stopping, reduce-learning rate on plateau to avoid over fititng\n",
        "callbacks_full = [\n",
        "    EarlyStopping(patience=8, verbose=1),\n",
        "    ReduceLROnPlateau(patience=5, verbose=1),\n",
        "    ModelCheckpoint('model-full-cwfid.h5', verbose=1, save_best_only=True)\n",
        "]\n",
        "\n",
        "\n",
        "# feeding training data to the model \n",
        "model_full_history = full_model.fit(x = x_train,\n",
        "                         y = y_train,\n",
        "                         batch_size = 5,\n",
        "                         epochs = 30,\n",
        "                         verbose = 1,\n",
        "                         validation_split = 0.2,\n",
        "                          callbacks = callbacks_full\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_-eMZM71Z80"
      },
      "source": [
        "# predicting for the full combined model\n",
        "pred_full = full_model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38bu_g1e1Z-S"
      },
      "source": [
        "# looking at the results predicted by our model\n",
        "\n",
        "i = 15\n",
        "plt.figure()\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(pred_full[i,:,:,2])\n",
        "plt.subplot(2,3,4)\n",
        "plt.imshow(y_test[i,:,:,2])\n",
        "plt.subplot(2,3,2)\n",
        "plt.imshow(pred_full[i,:,:,1])\n",
        "plt.subplot(2,3,5)\n",
        "plt.imshow(y_test[i,:,:,1])\n",
        "plt.subplot(2,3,3)\n",
        "plt.imshow(pred_full[i,:,:,0])\n",
        "plt.subplot(2,3,6)\n",
        "plt.imshow(y_test[i,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}